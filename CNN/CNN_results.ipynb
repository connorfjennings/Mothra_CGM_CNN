{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, math, json, random, numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "from architecture import UNetBasic, UNetDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/cj535/palmer_scratch/TNG50_cutouts/MW_sample_maps/packed_aug8_coldvel\"\n",
    "PATTERN  = \"TNG50_snap099_subid*_views10_aug8_C5_256x256.npy\"\n",
    "CHECKPOINTS_DIR = \"/home/cj535/palmer_scratch/CNN_checkpoints/coldgas_vel\"\n",
    "H, W = 256, 256\n",
    "R_MASK = 20                     # pixels\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 200\n",
    "FREEZE_ENCODER_EPOCHS = 10\n",
    "LR = 5e-4\n",
    "NUM_WORKERS = 1\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VEL_BINS = [(-300, -100), (-100, 100), (100, 300)]  # 3 input channels\n",
    "COMPRESSION = 'log10'\n",
    "\n",
    "def circular_outer_mask(H, W, R, device=\"cpu\"):\n",
    "    yy, xx = torch.meshgrid(torch.arange(H, device=device),\n",
    "                            torch.arange(W, device=device), indexing=\"ij\")\n",
    "    yc, xc = H/2.0, W/2.0\n",
    "    rr2 = (yy-yc)**2 + (xx-xc)**2\n",
    "    return (rr2 >= R**2).float().unsqueeze(0)  # (1,H,W)\n",
    "\n",
    "subid_re = re.compile(r\".*?_subid(?P<subid>\\d+)_views10_aug8_C5_256x256\\.npy$\")\n",
    "def find_packs(data_dir: str) -> Dict[str, np.ndarray]:\n",
    "    packs = {}\n",
    "    for path in glob.glob(os.path.join(data_dir, PATTERN)):\n",
    "        m = subid_re.match(path)\n",
    "        if not m: \n",
    "            continue\n",
    "        subid = m.group(\"subid\")\n",
    "        # Load fully into RAM as float32 ndarray\n",
    "        arr = np.load(path)  # already float32 per your save; if not: .astype(np.float32, copy=False)\n",
    "        if arr.shape[1] != 5 or arr.shape[2:] != (H, W):\n",
    "            raise RuntimeError(f\"Unexpected shape {arr.shape} in {path}\")\n",
    "        packs[subid] = arr\n",
    "    if not packs:\n",
    "        raise RuntimeError(\"No packs found. Check DATA_DIR/PATTERN.\")\n",
    "    return packs\n",
    "\n",
    "def compute_input_norm(packs: Dict[str, np.ndarray], subids: List[str],compression='log10'):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean/std over the 3 brightness channels using ONLY the train subids.\n",
    "    \"\"\"\n",
    "    s = np.zeros(3, dtype=np.float64)\n",
    "    q = np.zeros(3, dtype=np.float64)\n",
    "    n = 0\n",
    "    for sid in subids:\n",
    "        arr = packs[sid]          # (N,5,H,W)\n",
    "        x = arr[:, :3, :, :]      # (N,3,H,W)\n",
    "        if compression == 'sqrt':\n",
    "            x = np.sqrt(x)\n",
    "        elif compression == 'log10':\n",
    "            x = np.log10(x+1e-25)\n",
    "        n += x.shape[0]*H*W\n",
    "        s += x.reshape(-1,3,H,W).transpose(1,0,2,3).reshape(3,-1).sum(axis=1)\n",
    "        q += (x**2).reshape(-1,3,H,W).transpose(1,0,2,3).reshape(3,-1).sum(axis=1)\n",
    "    mean = s / n\n",
    "    var  = (q / n) - mean**2\n",
    "    std  = np.sqrt(var)#np.sqrt(np.clip(var, 1e-12, None))\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "class GalaxyPackDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Yields individual (viewÃ—aug) samples from a list of subids.\n",
    "    Expects memory-resident dict: subid -> ndarray (N,5,H,W).\n",
    "    Normalization (mean/std) is applied to input channels only.\n",
    "    \"\"\"\n",
    "    def __init__(self, packs: Dict[str, np.ndarray], subids: List[str], mean=None, std=None, compression='log10',r_mask=R_MASK):\n",
    "        self.subids = list(subids)\n",
    "        self.packs = packs\n",
    "        # Build an index: for each subid, iterate over samples\n",
    "        self.items = []  # list of (subid, local_idx)\n",
    "        for sid in self.subids:\n",
    "            N = self.packs[sid].shape[0]\n",
    "            self.items.extend((sid, i) for i in range(N))\n",
    "        self.mask = circular_outer_mask(H, W, r_mask, device=\"cpu\")  # (1,H,W)\n",
    "        self.mean = mean  # (3,)\n",
    "        self.std  = std   # (3,)\n",
    "        self.compression = compression\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid, i = self.items[idx]\n",
    "        sample = self.packs[sid][i]       # (5,H,W) float32\n",
    "        x = sample[:3]                    # (3,H,W)\n",
    "        y = sample[3:]                    # (2,H,W)\n",
    "        if self.compression == 'sqrt':\n",
    "            x = np.sqrt(x)\n",
    "        elif self.compression == 'log10':\n",
    "            x = np.log10(x+1e-25)\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            x = (x - self.mean[:, None, None]) / (self.std[:, None, None] + 1e-21)\n",
    "        # zero inputs in center\n",
    "        x = x * self.mask.numpy()\n",
    "        return {\n",
    "            \"x\": torch.from_numpy(x),     # float32\n",
    "            \"y\": torch.from_numpy(y),\n",
    "            \"mask\": self.mask.clone(),    # torch float32 (1,H,W)\n",
    "            \"subid\": sid\n",
    "        }\n",
    "\n",
    "packs = find_packs(DATA_DIR)\n",
    "all_subids = sorted(packs.keys(), key=lambda s: int(s))\n",
    "len(all_subids), list(all_subids)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same architecture as during training\n",
    "model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",       # good starting point; try \"resnet50\", \"convnext_tiny\", \"efficientnet-b3\", etc.\n",
    "        encoder_weights=\"imagenet\",    # <-- THIS loads pretrained encoder weights\n",
    "        in_channels=3,                 # your three velocity-bin brightness maps\n",
    "        classes=2,                     # 2 output channels (u, v)\n",
    "        activation=None                # regression: keep raw logits\n",
    "    ).to(DEVICE)\n",
    "#model = UNetDropout(in_channels=3,out_channels=4,p=0.2).to(DEVICE)\n",
    "#ckpt = torch.load(CHECKPOINTS_DIR+\"/fpn_cgm_best.pt\", map_location=DEVICE,weights_only=False)'\n",
    "ckpt = torch.load(CHECKPOINTS_DIR+\"/unet_cgm_best.pt\", map_location=DEVICE,weights_only=False)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "#model.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) split by subid (no leakage)\n",
    "groups = np.array([int(s) for s in all_subids])\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "# Split operates on indices; use subids as both samples and groups\n",
    "idx = np.arange(len(all_subids))\n",
    "train_idx, test_idx = next(splitter.split(idx, groups=groups))\n",
    "train_subids = [all_subids[i] for i in train_idx]\n",
    "test_subids  = [all_subids[i] for i in test_idx]\n",
    "print(f\"Train galaxies: {len(train_subids)} | Test galaxies: {len(test_subids)}\")\n",
    "\n",
    "# 3) compute input normalization on train only\n",
    "if \"mean\" in ckpt and \"std\" in ckpt:\n",
    "    mean, std = np.array(ckpt[\"mean\"], dtype=np.float32), np.array(ckpt[\"std\"], dtype=np.float32)\n",
    "else:\n",
    "    mean, std = compute_input_norm(packs, train_subids,compression=COMPRESSION)\n",
    "print(\"Input mean:\", mean, \"std:\", std)\n",
    "\n",
    "# 4) datasets / loaders\n",
    "train_ds = GalaxyPackDataset(packs, train_subids, mean=mean, std=std, r_mask=R_MASK,compression=COMPRESSION)\n",
    "test_ds  = GalaxyPackDataset(packs, test_subids,  mean=mean, std=std, r_mask=R_MASK,compression=COMPRESSION)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(\"cuda\" in DEVICE),\n",
    "                          persistent_workers=(NUM_WORKERS>0))\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(\"cuda\" in DEVICE),\n",
    "                          persistent_workers=(NUM_WORKERS>0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quiver(ax,u,v,scale,step=4):\n",
    "    ny, nx = v.shape\n",
    "    x = np.arange(nx)\n",
    "    y = np.arange(ny)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    # subsample\n",
    "    sl = (slice(None, None, step), slice(None, None, step))\n",
    "    Xs, Ys = X[sl], Y[sl]\n",
    "    Vx, Vy = u[sl], v[sl]\n",
    "    ax.quiver(Xs,Ys,Vx,Vy,scale=scale,color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_batch(loader, batch_idx=0):\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i == batch_idx:\n",
    "            x = batch[\"x\"].to(DEVICE, non_blocking=True)\n",
    "            y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "            m = batch[\"mask\"].to(DEVICE, non_blocking=True)\n",
    "            mask = m.cpu().numpy()[0,0]\n",
    "            mask = mask[None,None,:,:]\n",
    "            pred = model(x)\n",
    "            return x.cpu().numpy()*mask, y.cpu().numpy()*mask, pred.cpu().numpy()*mask, m.cpu().numpy(), batch[\"subid\"]\n",
    "    raise IndexError(f\"Batch {batch_idx} not found\")\n",
    "\n",
    "x_np, y_np, p_np, m_np, subids = get_batch(test_loader,2)\n",
    "\n",
    "i = 12  # which example in the batch to show\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(8,12),dpi=200)\n",
    "for j in range(3):\n",
    "    axs[0,j].imshow(x_np[i,j], cmap=\"inferno\",origin='lower'); axs[0,j].set_title(f\"Input ch{j}\")\n",
    "mask = m_np[i,0]\n",
    "#axs[0,3].imshow(mask, cmap=\"gray\"); axs[0,3].set_title(\"Mask\")\n",
    "\n",
    "uv = 0\n",
    "#vmin, vmax = np.percentile(np.concatenate([(y_np[:,uv]).ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[1,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[1,0].set_title(\"Pred u\")\n",
    "axs[1,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[1,1].set_title(\"True u\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "axs[1,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[1,2].set_title(\"Residual u\")\n",
    "\n",
    "uv = 1\n",
    "#vmin, vmax = np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[2,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,0].set_title(\"Pred v\")\n",
    "axs[2,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,1].set_title(\"True v\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "axs[2,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[2,2].set_title(\"Residual v\")\n",
    "axs[3,2].axis(\"off\"); axs[3,2].text(0,0.1,f\"subid {subids[i]}\", fontsize=12)\n",
    "\n",
    "scale = 4e3\n",
    "axs[3,0].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[3,0],p_np[i,0],p_np[i,1],scale)\n",
    "axs[3,0].set_title('pred quiver')\n",
    "\n",
    "axs[3,1].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[3,1],y_np[i,0],y_np[i,1],scale)\n",
    "axs[3,1].set_title('true quiver')\n",
    "\n",
    "\n",
    "for ax in axs.ravel(): ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
