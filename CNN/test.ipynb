{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, math, json, random, numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from unet_parts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- config ----------------\n",
    "DATA_DIR   =  \"/home/cj535/palmer_scratch/TNG50_cutouts/MW_sample_maps/packed_aug8\"  # folder with your .npy packs\n",
    "PATTERN    = \"TNG50_snap099_subid*_views10_aug8_C5_256x256.npy\"\n",
    "H, W = 256, 256\n",
    "R_MASK = 20                     # pixels\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LR = 2e-4\n",
    "NUM_WORKERS = 1\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VEL_BINS = [(-300, -100), (-100, 100), (100, 300)]  # 3 input channels\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# ---------- mask utilities ----------\n",
    "def circular_outer_mask(H: int, W: int, R: float, center=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Returns a mask of shape (1,H,W): 1 outside the circle of radius R, 0 inside.\n",
    "    center: (yc, xc) in pixel coords; default is image center.\n",
    "    \"\"\"\n",
    "    yc, xc = center if center is not None else (H/2.0, W/2.0)\n",
    "    yy, xx = torch.meshgrid(torch.arange(H, device=device),\n",
    "                            torch.arange(W, device=device), indexing=\"ij\")\n",
    "    rr2 = (yy - yc)**2 + (xx - xc)**2\n",
    "    mask = (rr2 >= R**2).float().unsqueeze(0)  # (1,H,W)\n",
    "    return mask\n",
    "\n",
    "# ---------- masked loss ----------\n",
    "def masked_mse(pred, target, mask, eps=1e-8):\n",
    "    \"\"\"\n",
    "    pred, target: (B,2,H,W)\n",
    "    mask: (B,1,H,W) with 1 where loss is computed (outside circle), 0 where ignored.\n",
    "    \"\"\"\n",
    "    diff2 = (pred - target)**2\n",
    "    wsum = mask.sum()\n",
    "    if wsum < eps:\n",
    "        # if everything is masked, return zero to avoid NaNs\n",
    "        return diff2.new_zeros(())\n",
    "    return (diff2 * mask).sum() / (wsum * pred.shape[1])  # average over valid pixels & channels\n",
    "\n",
    "def masked_mae(pred, target, mask, eps=1e-8):\n",
    "    diff = (pred - target).abs()\n",
    "    wsum = mask.sum()\n",
    "    if wsum < eps:\n",
    "        return diff.new_zeros(())\n",
    "    return (diff * mask).sum() / (wsum * pred.shape[1]).clamp_min(1.0)\n",
    "\n",
    "# ---------- simple UNet backbone (3->2, 256x256) ----------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, 3, padding=1), nn.BatchNorm2d(c_out), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(c_out, c_out, 3, padding=1), nn.BatchNorm2d(c_out), nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=2, base=32):\n",
    "        super().__init__()\n",
    "        # encoder\n",
    "        self.down1 = DoubleConv(in_ch, base)            # 256 -> 256\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(base, base*2))   # 256->128\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(base*2, base*4)) # 128->64\n",
    "        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(base*4, base*8)) # 64->32\n",
    "        self.down5 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(base*8, base*16))# 32->16\n",
    "\n",
    "        self.mid   = DoubleConv(base*16, base*32)       # 16 -> 16\n",
    "\n",
    "        # decoder (note the concat inputs!)\n",
    "        self.up5   = nn.ConvTranspose2d(base*32, base*16, 2, stride=2)          # 16->32\n",
    "        self.conv5 = DoubleConv(base*16 + base*8,  base*16)  # concat with d4\n",
    "\n",
    "        self.up4   = nn.ConvTranspose2d(base*16, base*8,  2, stride=2)          # 32->64\n",
    "        self.conv4 = DoubleConv(base*8  + base*4,  base*8)   # concat with d3\n",
    "\n",
    "        self.up3   = nn.ConvTranspose2d(base*8,  base*4,  2, stride=2)          # 64->128\n",
    "        self.conv3 = DoubleConv(base*4  + base*2,  base*4)   # concat with d2\n",
    "\n",
    "        self.up2   = nn.ConvTranspose2d(base*4,  base*2,  2, stride=2)          # 128->256\n",
    "        self.conv2 = DoubleConv(base*2  + base,    base*2)   # concat with d1\n",
    "\n",
    "        self.out   = nn.Conv2d(base*2, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)   # 256\n",
    "        d2 = self.down2(d1)  # 128\n",
    "        d3 = self.down3(d2)  # 64\n",
    "        d4 = self.down4(d3)  # 32\n",
    "        d5 = self.down5(d4)  # 16\n",
    "\n",
    "        m  = self.mid(d5)    # 16\n",
    "\n",
    "        u5 = self.up5(m)                         # 32\n",
    "        u5 = self.conv5(torch.cat([u5, d4], 1))  # match 32x32\n",
    "\n",
    "        u4 = self.up4(u5)                        # 64\n",
    "        u4 = self.conv4(torch.cat([u4, d3], 1))\n",
    "\n",
    "        u3 = self.up3(u4)                        # 128\n",
    "        u3 = self.conv3(torch.cat([u3, d2], 1))\n",
    "\n",
    "        u2 = self.up2(u3)                        # 256\n",
    "        u2 = self.conv2(torch.cat([u2, d1], 1))\n",
    "\n",
    "        return self.out(u2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subid_re = re.compile(r\".*?_subid(?P<subid>\\d+)_views10_aug8_C5_256x256\\.npy$\")\n",
    "def find_packs(data_dir: str) -> Dict[str, np.ndarray]:\n",
    "    packs = {}\n",
    "    for path in glob.glob(os.path.join(data_dir, PATTERN)):\n",
    "        m = subid_re.match(path)\n",
    "        if not m: \n",
    "            continue\n",
    "        subid = m.group(\"subid\")\n",
    "        # Load fully into RAM as float32 ndarray\n",
    "        arr = np.load(path)  # already float32 per your save; if not: .astype(np.float32, copy=False)\n",
    "        if arr.shape[1] != 5 or arr.shape[2:] != (H, W):\n",
    "            raise RuntimeError(f\"Unexpected shape {arr.shape} in {path}\")\n",
    "        packs[subid] = arr\n",
    "    if not packs:\n",
    "        raise RuntimeError(\"No packs found. Check DATA_DIR/PATTERN.\")\n",
    "    return packs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- dataset using in-RAM packs ----------------\n",
    "class GalaxyPackDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Yields individual (view×aug) samples from a list of subids.\n",
    "    Expects memory-resident dict: subid -> ndarray (N,5,H,W).\n",
    "    Normalization (mean/std) is applied to input channels only.\n",
    "    \"\"\"\n",
    "    def __init__(self, packs: Dict[str, np.ndarray], subids: List[str], mean=None, std=None, r_mask=R_MASK):\n",
    "        self.subids = list(subids)\n",
    "        self.packs = packs\n",
    "        # Build an index: for each subid, iterate over samples\n",
    "        self.items = []  # list of (subid, local_idx)\n",
    "        for sid in self.subids:\n",
    "            N = self.packs[sid].shape[0]\n",
    "            self.items.extend((sid, i) for i in range(N))\n",
    "        self.mask = circular_outer_mask(H, W, r_mask, device=\"cpu\")  # (1,H,W)\n",
    "        self.mean = mean  # (3,)\n",
    "        self.std  = std   # (3,)\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid, i = self.items[idx]\n",
    "        sample = self.packs[sid][i]       # (5,H,W) float32\n",
    "        x = sample[:3]                    # (3,H,W)\n",
    "        y = sample[3:]                    # (2,H,W)\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            x = (x - self.mean[:, None, None]) / (self.std[:, None, None] + 1e-21)\n",
    "        # zero inputs in center\n",
    "        x = x * self.mask.numpy()\n",
    "        return {\n",
    "            \"x\": torch.from_numpy(x),     # float32\n",
    "            \"y\": torch.from_numpy(y),\n",
    "            \"mask\": self.mask.clone(),    # torch float32 (1,H,W)\n",
    "            \"subid\": sid\n",
    "        }\n",
    "\n",
    "def compute_input_norm(packs: Dict[str, np.ndarray], subids: List[str]):\n",
    "    \"\"\"\n",
    "    Compute per-channel mean/std over the 3 brightness channels using ONLY the train subids.\n",
    "    \"\"\"\n",
    "    s = np.zeros(3, dtype=np.float64)\n",
    "    q = np.zeros(3, dtype=np.float64)\n",
    "    n = 0\n",
    "    for sid in subids:\n",
    "        arr = packs[sid]          # (N,5,H,W)\n",
    "        x = arr[:, :3, :, :]      # (N,3,H,W)\n",
    "        n += x.shape[0]*H*W\n",
    "        s += x.reshape(-1,3,H,W).transpose(1,0,2,3).reshape(3,-1).sum(axis=1)\n",
    "        q += (x**2).reshape(-1,3,H,W).transpose(1,0,2,3).reshape(3,-1).sum(axis=1)\n",
    "    mean = s / n\n",
    "    var  = (q / n) - mean**2\n",
    "    std  = np.sqrt(var)#np.sqrt(np.clip(var, 1e-12, None))\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "# ---------------- training / eval ----------------\n",
    "def train_one_epoch(model, loader, opt, scaler=None):\n",
    "    model.train()\n",
    "    tot_loss, tot_mae = 0.0, 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"x\"].to(DEVICE, non_blocking=True)\n",
    "        y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "        m = batch[\"mask\"].to(DEVICE, non_blocking=True)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        if scaler is not None:\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                pred = model(x)\n",
    "                loss = masked_mse(pred, y, m)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            pred = model(x); loss = masked_mse(pred, y, m)\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "        mae = masked_mae(pred.detach(), y, m).item()\n",
    "        tot_loss += loss.item(); tot_mae += mae\n",
    "    n = len(loader)\n",
    "    return tot_loss/n, tot_mae/n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    tot_loss, tot_mae = 0.0, 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"x\"].to(DEVICE, non_blocking=True)\n",
    "        y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "        m = batch[\"mask\"].to(DEVICE, non_blocking=True)\n",
    "        pred = model(x)\n",
    "        loss = masked_mse(pred, y, m)\n",
    "        mae  = masked_mae(pred, y, m).item()\n",
    "        tot_loss += loss.item(); tot_mae += mae\n",
    "    n = len(loader)\n",
    "    return tot_loss/n, tot_mae/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "packs = find_packs(DATA_DIR)\n",
    "all_subids = sorted(packs.keys(), key=lambda s: int(s))\n",
    "print(f\"Loaded {len(all_subids)} galaxies into RAM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) split by subid (no leakage)\n",
    "groups = np.array([int(s) for s in all_subids])\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "# Split operates on indices; use subids as both samples and groups\n",
    "idx = np.arange(len(all_subids))\n",
    "train_idx, test_idx = next(splitter.split(idx, groups=groups))\n",
    "train_subids = [all_subids[i] for i in train_idx]\n",
    "test_subids  = [all_subids[i] for i in test_idx]\n",
    "print(f\"Train galaxies: {len(train_subids)} | Test galaxies: {len(test_subids)}\")\n",
    "\n",
    "# 3) compute input normalization on train only\n",
    "mean, std = compute_input_norm(packs, train_subids)\n",
    "print(\"Input mean:\", mean, \"std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) datasets / loaders\n",
    "train_ds = GalaxyPackDataset(packs, train_subids, mean=mean, std=std, r_mask=R_MASK)\n",
    "test_ds  = GalaxyPackDataset(packs, test_subids,  mean=mean, std=std, r_mask=R_MASK)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(\"cuda\" in DEVICE),\n",
    "                          persistent_workers=(NUM_WORKERS>0))\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=(\"cuda\" in DEVICE),\n",
    "                          persistent_workers=(NUM_WORKERS>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) model/optim\n",
    "model = UNetSmall(in_ch=3, out_ch=2, base=32).to(DEVICE)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scaler= torch.amp.GradScaler(enabled=(\"cuda\" in DEVICE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) train\n",
    "EPOCHS = 1\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "#os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "ckpt_path = os.path.join(\"checkpoints\", \"unet_cgm_best_test.pt\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_mae = train_one_epoch(model, train_loader, opt, scaler)\n",
    "    va_loss, va_mae = evaluate(model, test_loader)\n",
    "    print(f\"[{epoch:03d}/{EPOCHS}] train: loss {tr_loss:.5f}, mae {tr_mae:.5f} | \"\n",
    "          f\"val: loss {va_loss:.5f}, mae {va_mae:.5f}\")\n",
    "\n",
    "    if va_loss < best_val:\n",
    "        best_val = va_loss\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"mean\": mean, \"std\": std,\n",
    "            \"epoch\": epoch, \"val_loss\": va_loss,\n",
    "            \"config\": {\n",
    "                \"R_MASK\": R_MASK, \"H\": H, \"W\": W,\n",
    "                \"BATCH_SIZE\": BATCH_SIZE, \"LR\": LR\n",
    "            }\n",
    "        }, ckpt_path)\n",
    "        print(f\"  ✓ saved best → {ckpt_path}\")\n",
    "\n",
    "print(\"Done. Best val loss:\", best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
