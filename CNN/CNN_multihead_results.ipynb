{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, math, json, random, numpy as np\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import segmentation_models_pytorch as smp\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "from architecture import UNetBasic, UNetDropout, UNetMultiHeadProfiles\n",
    "from seg_models_multihead_train import *\n",
    "import diptest\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = \"/home/cj535/palmer_scratch/TNG50_cutouts/MW_sample_maps/packed_aug8_weightemitvel\"\n",
    "#PATTERN  = \"TNG50_snap099_subid*_views10_aug8_C5_256x256.npy\"\n",
    "CATALOG    = \"/home/cj535/palmer_scratch/TNG50_cutouts/MW_sample_maps/catalog_pkls/coldvel_1e-22mask_C8_20_200_profile.pkl\"\n",
    "CHECKPOINTS_DIR = \"/home/cj535/palmer_scratch/CNN_checkpoints/coldgas_multihead_C8\"\n",
    "CHECKPOINTS_NAME = \"UNetMultihead\"\n",
    "H, W = 256, 256\n",
    "IN_CHANNELS = 5            # mask + bolometric + 3 vel bins\n",
    "TARGET_C = 3                # u,v,w\n",
    "ALEOTORIC_ERRORS = 0\n",
    "OUT_CHANNELS = (ALEOTORIC_ERRORS+1) * TARGET_C\n",
    "R_MASK = 15                     # pixels\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "FREEZE_ENCODER_EPOCHS = 3\n",
    "LR = 3e-4\n",
    "NUM_WORKERS = 1\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#VEL_BINS = [(-300, -100), (-100, 100), (100, 300)]  # 3 input channels\n",
    "COMPRESSION = 'log10'\n",
    "# weights\n",
    "LAMBDA_MAPS  = 3.0\n",
    "LAMBDA_MASS  = 1.0\n",
    "LAMBDA_FLOW  = 1.0\n",
    "\n",
    "shell_midpoints = np.arange(20,205,5)\n",
    "K=shell_midpoints.shape[0]\n",
    "L=shell_midpoints.shape[0]\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "catalog_path = CATALOG\n",
    "df = pd.read_pickle(catalog_path)\n",
    "# ensure subids are strings (since your packs/dataset use string keys)\n",
    "df.index = df.index.astype(str)\n",
    "\n",
    "# 1) load all galaxy packs into RAM from catalog\n",
    "packs = {}\n",
    "subid_to_Mprof = {}\n",
    "subid_to_Fprof = {}\n",
    "\n",
    "for sid in df.index:\n",
    "    row = df.loc[sid]\n",
    "    arr = np.load(row[\"maps_path\"])  # (N, C, H, W)\n",
    "    packs[sid] = arr.astype(np.float32, copy=False)\n",
    "\n",
    "    subid_to_Mprof[sid] = row[\"mass_profile\"]  # (K,)\n",
    "    subid_to_Fprof[sid] = row[\"flow_profile\"]  # (L,)\n",
    "\n",
    "all_subids = sorted(packs.keys(), key=lambda s: int(s))\n",
    "print(f\"Loaded {len(all_subids)} galaxies into RAM (with 1D profiles).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) split by subid (no leakage)\n",
    "groups = np.array([int(s) for s in all_subids])\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "# Split operates on indices; use subids as both samples and groups\n",
    "idx = np.arange(len(all_subids))\n",
    "train_idx, test_idx = next(splitter.split(idx, groups=groups))\n",
    "train_subids = [all_subids[i] for i in train_idx]\n",
    "test_subids  = [all_subids[i] for i in test_idx]\n",
    "print(f\"Train galaxies: {len(train_subids)} | Test galaxies: {len(test_subids)}\")\n",
    "#\n",
    "\n",
    "K = len(next(iter(subid_to_Mprof.values())))\n",
    "L = len(next(iter(subid_to_Fprof.values())))\n",
    "\n",
    "# 3) compute input normalization on train only\n",
    "\n",
    "M_mean, M_std = compute_profile_norm(subid_to_Mprof, train_subids, mode=\"log10\")\n",
    "\n",
    "def compute_z_norm(mapping, train_subids):\n",
    "    arrs = [np.asarray(mapping[s], np.float32)[None, :] for s in train_subids]\n",
    "    A = np.concatenate(arrs, axis=0)\n",
    "    return A.mean(0).astype(np.float32), (A.std(0) + 1e-8).astype(np.float32)\n",
    "\n",
    "F_mean, F_std = compute_z_norm(subid_to_Fprof, train_subids)\n",
    "\n",
    "mean, std = compute_input_norm(packs, train_subids, compression=COMPRESSION, inC=IN_CHANNELS, channel0mask=True)\n",
    "print(\"Input mean:\", mean, \"std:\", std)\n",
    "\n",
    "# 4) datasets / loaders\n",
    "train_ds = GalaxyPackDataset(\n",
    "    packs, train_subids,\n",
    "    mean=mean, std=std,\n",
    "    r_mask=R_MASK, compression=COMPRESSION,\n",
    "    in_channels=IN_CHANNELS,\n",
    "    subid_to_Mprof=subid_to_Mprof,\n",
    "    subid_to_Fprof=subid_to_Fprof,\n",
    "    Mprof_mode=\"log10\", Fprof_mode=None,\n",
    "    M_mean=M_mean, M_std=M_std,\n",
    "    F_mean=F_mean, F_std=F_std,\n",
    ")\n",
    "test_ds = GalaxyPackDataset(\n",
    "    packs, test_subids,\n",
    "    mean=mean, std=std,\n",
    "    r_mask=R_MASK, compression=COMPRESSION,\n",
    "    in_channels=IN_CHANNELS,\n",
    "    subid_to_Mprof=subid_to_Mprof,\n",
    "    subid_to_Fprof=subid_to_Fprof,\n",
    "    Mprof_mode=\"log10\", Fprof_mode=None,\n",
    "    M_mean=M_mean, M_std=M_std,\n",
    "    F_mean=F_mean, F_std=F_std,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(\"cuda\" in DEVICE),\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(\"cuda\" in DEVICE),\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same architecture as during training\n",
    "MODEL = UNetMultiHeadProfiles(in_channels=IN_CHANNELS,out_channels=OUT_CHANNELS,p=0.2,K=K,L=L)\n",
    "model = MODEL.to(DEVICE)\n",
    "#ckpt = torch.load(CHECKPOINTS_DIR+\"/fpn_cgm_best.pt\", map_location=DEVICE,weights_only=False)'\n",
    "ckpt = torch.load(CHECKPOINTS_DIR+\"/UNetMultihead_cgm_best.pt\", map_location=DEVICE,weights_only=False)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "#model.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quiver(ax,u,v,scale,step=2,color='white'):\n",
    "    ny, nx = v.shape\n",
    "    x = np.arange(nx)\n",
    "    y = np.arange(ny)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    # subsample\n",
    "    sl = (slice(None, None, step), slice(None, None, step))\n",
    "    Xs, Ys = X[sl], Y[sl]\n",
    "    Vx, Vy = u[sl], v[sl]\n",
    "    qu = ax.quiver(Xs,Ys,Vx,Vy,scale=scale,color=color)\n",
    "    return qu\n",
    "@torch.no_grad()\n",
    "def get_batch(loader, batch_idx=0,make_arrays=True,profiles=False):\n",
    "    model.eval()\n",
    "    for i, batch in enumerate(loader):\n",
    "        if i == batch_idx:\n",
    "            x = batch[\"x\"].to(DEVICE, non_blocking=True)\n",
    "            y = batch[\"y\"].to(DEVICE, non_blocking=True)\n",
    "            m = batch[\"mask\"].to(DEVICE, non_blocking=True)\n",
    "            Mprof = batch[\"Mprof\"].to(DEVICE)\n",
    "            Fprof= batch[\"Fprof\"].to(DEVICE)\n",
    "            \n",
    "            out = model(x)\n",
    "            y_pred = out[\"maps\"]\n",
    "            Mprof_pred = out[\"mass_prof\"]\n",
    "            Fprof_pred = out[\"flow_prof\"]\n",
    "            if make_arrays:\n",
    "                mask = m.cpu().numpy()\n",
    "                if profiles:\n",
    "                    return x.cpu().numpy(), y.cpu().numpy()*mask, y_pred.cpu().numpy()*mask, m.cpu().numpy(), batch[\"subid\"],\\\n",
    "                    Mprof.cpu().numpy(),Fprof.cpu().numpy(),Mprof_pred.cpu().numpy(),Fprof_pred.cpu().numpy()\n",
    "                else:\n",
    "                    return x.cpu().numpy(), y.cpu().numpy()*mask, y_pred.cpu().numpy()*mask, m.cpu().numpy(), batch[\"subid\"]\n",
    "            else:\n",
    "                mask = m\n",
    "                if profiles:\n",
    "                    return x, y*mask, y_pred*mask, mask, batch[\"subid\"],\\\n",
    "                    Mprof,Fprof,Mprof_pred,Fprof_pred\n",
    "                else:\n",
    "                    return x, y*mask, y_pred*mask, mask, batch[\"subid\"]\n",
    "    raise IndexError(f\"Batch {batch_idx} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_mc_dropout_only(model: nn.Module):\n",
    "    model.eval()  # keep BN frozen\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.Dropout3d)):\n",
    "            m.train()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_mc_multihead(model, x, mask=None, T=50, device=\"cuda\"):\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    if mask is not None:\n",
    "        mask = mask.to(device, non_blocking=True)\n",
    "\n",
    "    enable_mc_dropout_only(model)\n",
    "\n",
    "    preds_maps = []\n",
    "    preds_M = []\n",
    "    preds_F = []\n",
    "\n",
    "    for _ in range(T):\n",
    "        out = model(x)\n",
    "        preds_maps.append(out[\"maps\"])\n",
    "        preds_M.append(out[\"mass_prof\"])\n",
    "        preds_F.append(out[\"flow_prof\"])\n",
    "\n",
    "    preds_maps = torch.stack(preds_maps, 0)     # (T,B,C_or_2C,H,W)\n",
    "    preds_M    = torch.stack(preds_M, 0)        # (T,B,K)\n",
    "    preds_F    = torch.stack(preds_F, 0)        # (T,B,L)\n",
    "\n",
    "    # reuse the above logic for maps...\n",
    "    # and then for profiles:\n",
    "    M_mu   = preds_M.mean(0)                    # (B,K)\n",
    "    M_std  = preds_M.std(0, unbiased=True)      # (B,K)\n",
    "    F_mu   = preds_F.mean(0)                    # (B,L)\n",
    "    F_std  = preds_F.std(0, unbiased=True)      # (B,L)\n",
    "\n",
    "    out = {\n",
    "        # map fields ('mu', 'std_epistemic', etc.),\n",
    "        # plus:\n",
    "        \"mass_mu\": M_mu,\n",
    "        \"mass_std_epistemic\": M_std,\n",
    "        \"flow_mu\": F_mu,\n",
    "        \"flow_std_epistemic\": F_std,\n",
    "    }\n",
    "\n",
    "    if mask is not None:\n",
    "        # only spatial fields need masking\n",
    "        for k in list(out.keys()):\n",
    "            if out[k].ndim == 4:  # (B,C,H,W) shapes\n",
    "                out[k] = out[k] * mask\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np, y_np, p_np, m_np, subids, Mprof,Fprof,Mprof_pred,Fprof_pred = get_batch(test_loader,10,profiles=True)\n",
    "i=0\n",
    "plt.plot(Mprof[i],color='blue')\n",
    "plt.plot(Mprof_pred[i],color='blue',linestyle=':')\n",
    "plt.plot(Fprof[i],color='red')\n",
    "plt.plot(Fprof_pred[i],color='red',linestyle=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np, y_np, p_np, m_np, subids, Mprof,Fprof,Mprof_pred,Fprof_pred = get_batch(test_loader,0,profiles=True)\n",
    "i = 0  # which example in the batch to show\n",
    "step = 4\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,12),dpi=200)\n",
    "scale = 4e3\n",
    "axs[0].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[0],p_np[i,0],p_np[i,1],scale,step=step)\n",
    "axs[0].set_title('pred quiver')\n",
    "\n",
    "axs[1].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[1],y_np[i,0],y_np[i,1],scale,step=step)\n",
    "axs[1].set_title('true quiver')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "x_np, y_np, p_np, m_np, subids = get_batch(test_loader,25,make_arrays=False)\n",
    "i=0\n",
    "p_np = p_np.cpu().detach().numpy()\n",
    "y_np = y_np.cpu().detach().numpy()\n",
    "x = x_np[i]\n",
    "x = x[None,:,:,:]\n",
    "T = 100\n",
    "enable_mc_dropout_only(model)\n",
    "MC = []\n",
    "for t in tqdm.tqdm(range(T)):\n",
    "    p = model(x)*m_np\n",
    "    MC.append(p[0].cpu().detach().numpy())\n",
    "MC = np.array(MC)\n",
    "uncertainty = np.std(MC,axis=0)\n",
    "x_np = x_np.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 8e3\n",
    "fig, ax = plt.subplots(figsize=(6,6),dpi=200)\n",
    "step=4\n",
    "\n",
    "ax.imshow(x_np[i,3], cmap=\"viridis\",origin='lower')\n",
    "qu1 = add_quiver(ax,y_np[i,0],y_np[i,1],scale,color='pink')\n",
    "#qu2 = add_quiver(ax,p_np[i,0],p_np[i,1],scale)\n",
    "u,v = p_np[i,0],p_np[i,1]\n",
    "ny, nx = v.shape\n",
    "x = np.arange(nx)\n",
    "y = np.arange(ny)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "# subsample\n",
    "sl = (slice(None, None, step), slice(None, None, step))\n",
    "Xs, Ys = X[sl], Y[sl]\n",
    "Vx, Vy = u[sl], v[sl]\n",
    "qu2 = ax.quiver(Xs,Ys,Vx,Vy,scale=scale,color='white')\n",
    "ax.axis(\"off\")\n",
    "\n",
    "def update(frame):\n",
    "    u,v = MC[frame,0], MC[frame,1]\n",
    "    Vx = u[::step, ::step]\n",
    "    Vy = v[::step, ::step]\n",
    "    qu2.set_UVC(Vx, Vy)   # update only U,V\n",
    "\n",
    "fps = 120\n",
    "anim = FuncAnimation(fig, update, frames=T, interval=1000 / fps, blit=False)\n",
    "writer = PillowWriter(fps=fps)\n",
    "anim.save('plots/errors5.gif', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(MC[0,0],origin='lower',cmap='RdBu',vmin=-300,vmax=300)\n",
    "plt.scatter(135,170,color='k')\n",
    "plt.show()\n",
    "x_th = np.arange(MC.shape[0])\n",
    "multimodal_map = np.ones_like(MC[0])\n",
    "for i in tqdm.tqdm(range(multimodal_map.shape[1])):\n",
    "    for j in range(multimodal_map.shape[2]):\n",
    "        dip,pval = diptest.diptest(MC[:,0,i,j])\n",
    "        multimodal_map[0,i,j]=pval\n",
    "        dip,pval = diptest.diptest(MC[:,1,i,j])\n",
    "        multimodal_map[1,i,j]=pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(multimodal_map[0],vmin=0,vmax=0.10,origin='lower',alpha=0.5,zorder=10)\n",
    "#plt.colorbar()\n",
    "i=6\n",
    "plt.imshow(uncertainty[0],origin='lower',cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 2\n",
    "i = 1  # which example in the batch to show\n",
    "\n",
    "\n",
    "x_np, y_np, p_np, m_np, subids = get_batch(test_loader,batch_num,make_arrays=False)\n",
    "p_np = p_np.cpu().detach().numpy()\n",
    "y_np = y_np.cpu().detach().numpy()\n",
    "x = x_np[i]\n",
    "x = x[None,:,:,:]\n",
    "T = 500\n",
    "enable_mc_dropout_only(model)\n",
    "MC = []\n",
    "for t in tqdm.tqdm(range(T)):\n",
    "    p = model(x)*m_np\n",
    "    MC.append(p[0].cpu().detach().numpy())\n",
    "MC = np.array(MC)\n",
    "uncertainty = np.std(MC,axis=0)\n",
    "x_np = x_np.cpu().detach().numpy()\n",
    "m_np = m_np.cpu().detach().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(12,12),dpi=200)\n",
    "for j in range(4):\n",
    "    axs[0,j].imshow(x_np[i,j], cmap=\"inferno\",origin='lower'); axs[0,j].set_title(f\"Input ch{j}\")\n",
    "#mask = m_np[i,0]\n",
    "#axs[0,3].imshow(mask, cmap=\"gray\"); axs[0,3].set_title(\"Mask\")\n",
    "\n",
    "uv = 0\n",
    "#vmin, vmax = np.percentile(np.concatenate([(y_np[:,uv]).ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[1,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[1,0].set_title(\"Pred u\")\n",
    "axs[1,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[1,1].set_title(\"True u\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "#axs[1,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[1,2].set_title(\"Residual u\")\n",
    "axs[1,2].imshow((p_np[i,uv]-y_np[i,uv])**2, cmap=\"viridis\",vmin=0, vmax=300**2,origin='lower'); axs[1,2].set_title(\"Residual^2 u\")\n",
    "axs[1,3].imshow((uncertainty[uv])**2, cmap=\"viridis\",vmin=0, vmax=300**2,origin='lower'); axs[1,3].set_title(\"var u\")\n",
    "\n",
    "uv = 1\n",
    "#vmin, vmax = np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[2,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,0].set_title(\"Pred v\")\n",
    "axs[2,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,1].set_title(\"True v\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "#axs[2,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[2,2].set_title(\"Residual v\")\n",
    "axs[2,2].imshow((p_np[i,uv]-y_np[i,uv])**2, cmap=\"viridis\",vmin=0, vmax=200**2,origin='lower'); axs[2,2].set_title(\"Residual^2 v\")\n",
    "axs[2,3].imshow((uncertainty[uv])**2, cmap=\"viridis\",vmin=0, vmax=50**2,origin='lower'); axs[2,3].set_title(\"var v\")\n",
    "\n",
    "scale = 4e3\n",
    "axs[3,0].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[3,0],p_np[i,0],p_np[i,1],scale)\n",
    "axs[3,0].set_title('pred quiver')\n",
    "\n",
    "axs[3,1].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[3,1],y_np[i,0],y_np[i,1],scale)\n",
    "axs[3,1].set_title('true quiver')\n",
    "\n",
    "\n",
    "for ax in axs.ravel(): ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np, y_np, p_np, m_np, subids = get_batch(test_loader,2)\n",
    "\n",
    "i = 10  # which example in the batch to show\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(12,12),dpi=200)\n",
    "for j in range(4):\n",
    "    axs[0,j].imshow(x_np[i,j], cmap=\"inferno\",origin='lower'); axs[0,j].set_title(f\"Input ch{j}\")\n",
    "mask = m_np[i,0]\n",
    "#axs[0,3].imshow(mask, cmap=\"gray\"); axs[0,3].set_title(\"Mask\")\n",
    "\n",
    "uv = 0\n",
    "#vmin, vmax = np.percentile(np.concatenate([(y_np[:,uv]).ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[1,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[1,0].set_title(\"Pred u\")\n",
    "axs[1,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[1,1].set_title(\"True u\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "#axs[1,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[1,2].set_title(\"Residual u\")\n",
    "axs[1,2].imshow((p_np[i,uv]-y_np[i,uv])**2, cmap=\"viridis\",vmin=0, vmax=vlim**2,origin='lower'); axs[1,2].set_title(\"Residual u\")\n",
    "#axs[1,3].imshow(np.sqrt(np.abs(p_np[i,uv+2])),origin='lower',vmin=0)\n",
    "\n",
    "uv = 1\n",
    "#vmin, vmax = np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[2,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,0].set_title(\"Pred v\")\n",
    "axs[2,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,1].set_title(\"True v\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "axs[2,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[2,2].set_title(\"Residual v\")\n",
    "#axs[3,2].axis(\"off\"); axs[3,2].text(0,0.1,f\"subid {subids[i]}\", fontsize=12)\n",
    "\n",
    "uv = 2\n",
    "#vmin, vmax = np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])\n",
    "vlim = np.max(np.abs(np.percentile(np.concatenate([y_np[:,uv].ravel(), p_np[:,uv].ravel()]), [2,98])))\n",
    "axs[2,0].imshow(p_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,0].set_title(\"Pred w\")\n",
    "axs[2,1].imshow(y_np[i,uv], cmap=\"RdBu\", vmin=-vlim, vmax=vlim,origin='lower'); axs[2,1].set_title(\"True w\")\n",
    "vlim = np.max(np.abs(np.percentile((p_np[i,uv]-y_np[i,uv]).ravel(), [2,98])))\n",
    "axs[2,2].imshow(p_np[i,uv]-y_np[i,uv], cmap=\"coolwarm\",vmin=-vlim, vmax=vlim,origin='lower'); axs[2,2].set_title(\"Residual v\")\n",
    "#axs[3,2].axis(\"off\"); axs[3,2].text(0,0.1,f\"subid {subids[i]}\", fontsize=12)\n",
    "\n",
    "\n",
    "scale = 4e3\n",
    "axs[3,0].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[3,0],p_np[i,0],p_np[i,1],scale)\n",
    "axs[3,0].set_title('pred quiver')\n",
    "\n",
    "axs[3,1].imshow(x_np[i,1], cmap=\"inferno\",origin='lower')\n",
    "add_quiver(axs[3,1],y_np[i,0],y_np[i,1],scale)\n",
    "axs[3,1].set_title('true quiver')\n",
    "\n",
    "\n",
    "for ax in axs.ravel(): ax.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
